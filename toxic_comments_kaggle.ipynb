{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ija2Dq7KwRdW"
   },
   "source": [
    "# Toxic Comment Classification with Deep Learning\n",
    "\n",
    "A CTAWG demo with PyTorch fast.ai and Keras. [View the Toxic Comment Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) on Kaggle.\n",
    "\n",
    "In Colab: Click View -> Table of Contents to show an outline to the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sDqLgkSOwcj-"
   },
   "source": [
    "Steps:\n",
    "- Sign up for Kaggle account\n",
    "- Download data from Kaggle\n",
    "- Clean data\n",
    "- Fine-tune language model\n",
    "- Build classifier\n",
    "- Generate predictions\n",
    "- Submit to leaderboard (using Kaggle CLI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTBBwQ-_ZjFm"
   },
   "source": [
    "Todo:\n",
    "- Replace hate speech example prediction text with a hateful comment from the training data (or test).\n",
    "- Fix manual install of fast.ai module which doesn't persist across workspace restarts in FloydHub\n",
    "- Fix processed data being saved into the data-raw folder\n",
    "- Multi-output model for all 6 outcomes (fast.ai lesson 8/9 in part 2)\n",
    "   - Also see https://forums.fast.ai/t/creating-a-multi-label-torchtext-dataset/11960\n",
    "- Generate predictions for all models (see bottom of https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline)\n",
    "- Compare to BERT, GPT-2, standard LSTM/CNN, etc.\n",
    "- Handle class imbalance (or just ignore?)\n",
    "- Get working on Benten, home desktop, and XSEDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TE5BYdd8Acth"
   },
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wp-mCje79gX5"
   },
   "source": [
    "### Setup Google Colab\n",
    "\n",
    "Go to Runtime -> Change runtime type and under \"Hardware Accelerator\" select \"GPU\".\n",
    "\n",
    "Or use FloydHub - much faster for actual training, although expensive.\n",
    "\n",
    "The cell below should print \"true\" if the GPU is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xqvfnBoS9u1R",
    "outputId": "a1a5ebe4-1f27-4c2d-f967-356aaba3064f"
   },
   "outputs": [],
   "source": [
    "# Test pytorch GPU access.\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANsE-ddGw8RW"
   },
   "source": [
    "### Setup Kaggle Account and Data\n",
    "\n",
    "Using https://www.kaggle.com/general/51898 as a guide.\n",
    "\n",
    "Go to [Kaggle](https://www.kaggle.com)\n",
    "- Create an acocunt, or login to your existing account\n",
    "- Click \"MyAccount\"\n",
    "- Create \"New API Token\" button\n",
    "- This will automatically download a \"kaggle.json\" file.\n",
    "- Run the cell below and upload that file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "YdJrOVB9wPQm",
    "outputId": "376a59e9-e548-48e4-9f66-46d06924334e"
   },
   "outputs": [],
   "source": [
    "# Run this in CoLab; in FloydHub upload via JupyterLab.\n",
    "# Run this cell, then browse to your downloaded kaggle.json and upload.\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HL5Wjl9GyRxH"
   },
   "source": [
    "Setup Kaggle profile. Code via https://www.kaggle.com/general/51898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yaCTE2KgyPJI",
    "outputId": "38157c7b-549b-4e13-e439-43c710df49a6"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle && mv kaggle.json ~/.kaggle\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!cat ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-pPR3W7Tz8SQ"
   },
   "source": [
    "### Install python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "J4wwdZIgz6En",
    "outputId": "9d03532b-d991-4798-a210-6b344470b22d"
   },
   "outputs": [],
   "source": [
    "# Install kaggle packages (not needed on floydhub)\n",
    "# !pip3 install -q kaggle kaggle-cli\n",
    "# Already installed: pytorch 1.0.1, torchvision, numpy, fast.ai, tensorflow-gpu, keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX1EEaJd7yuw"
   },
   "outputs": [],
   "source": [
    "# Install GitHub version of fast.ai\n",
    "!git clone https://github.com/fastai/fastai\n",
    "# Run this in a single line because \"!cd\" does not persist across lines.\n",
    "# NOTE: on FloydHub I had to manually edit 3 files in the tools/ directory to specify python 3.6 rather than 3.5\n",
    "!cd fastai && tools/run-after-git-clone && pip install -e \".[dev]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sDd2PLPs0alv"
   },
   "source": [
    "Download the data files for this competition. [See kaggle API documentation](https://github.com/Kaggle/kaggle-api) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "oPhCNNlT0ZUg",
    "outputId": "adb6b5c2-2d4d-4a12-9894-de41851caefc"
   },
   "outputs": [],
   "source": [
    "# Store our kaggle data in the data-raw subdirectory to stay organized.\n",
    "# Also create a folder for processed data.\n",
    "!mkdir -p data-raw data\n",
    "\n",
    "# This will download zipfiles of sample_submission.csv, test.csv, train.csv, test_labels.csv into the current directory\n",
    "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge -p data-raw\n",
    "\n",
    "# We need to quote the \"*\" in order for unzip to work on multiple files.\n",
    "# -o: overwrite existing files without prompting\n",
    "# -q: quiet mode\n",
    "!unzip -oq 'data-raw/*.zip' -d data-raw\n",
    "\n",
    "# Check the number of lines in each of these new csv files.\n",
    "!wc -l data-raw/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJ8Lx7yIASEy"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kXEQ3cPV8nIo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.51.dev0\n"
     ]
    }
   ],
   "source": [
    "# This will also import pandas as pd apparently.\n",
    "# If this fails make sure that fastai is installed from github above.\n",
    "import fastai\n",
    "from fastai.text import *\n",
    "\n",
    "# Should be 1.0.51.dev0, not 1.0.42 (too old)\n",
    "print(fastai.__version__)\n",
    "\n",
    "raw_data = Path(\"data-raw\")\n",
    "data_path = Path(\"data\")\n",
    "\n",
    "#bs = 8\n",
    "#bs = 48\n",
    "#bs = 128 # works on tesla V100 (FloydHub)\n",
    "bs = 160 # works for LM on tesla V100 (FloydHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "njN8bMqJ80sX",
    "outputId": "05e30b9d-7d8b-46f6-b999-e1b4d6c48f45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "1             0        0       0       0              0  \n",
      "2             0        0       0       0              0  \n",
      "3             0        0       0       0              0  \n",
      "4             0        0       0       0              0   \n",
      "\n",
      "\n",
      "toxic            0.095844\n",
      "severe_toxic     0.009996\n",
      "obscene          0.052948\n",
      "threat           0.002996\n",
      "insult           0.049364\n",
      "identity_hate    0.008805\n",
      "dtype: float64 \n",
      "\n",
      "0    158166\n",
      "1      1405\n",
      "Name: identity_hate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(raw_data / \"train.csv\")\n",
    "\n",
    "print(df.head(), \"\\n\"*2)\n",
    "\n",
    "# Last 6 columns are the outcomes.\n",
    "outcomes = df.columns[-6:]\n",
    "\n",
    "# Examine the outcome distribution. Identity hate is only 0.9% positive!\n",
    "print(df[outcomes].mean(axis = 0), \"\\n\")\n",
    "\n",
    "# We have only 1,405 positive cases vs. 158,166 negative cases :/\n",
    "print(df[\"identity_hate\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "0mhtPDAmBdfT",
    "outputId": "9772e0fc-1a1d-405a-cb90-0c6bb0859b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27 \n",
      "\n",
      "                   id                                       comment_text  \\\n",
      "42   001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n",
      "105  00472b8e2d38d1ea         A pair of jew-hating weiner nazi schmucks.   \n",
      "176  006b94add72ed61c  I think that your a Fagget get a oife and burn...   \n",
      "218  008e0818dde894fb  Kill all niggers. \\n\\nI have hard, that others...   \n",
      "238  0097dd5c29bf7a15  u r a tw@ fuck off u gay boy.U r smelly.Fuck u...   \n",
      "\n",
      "     toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
      "42       1             0        1       0       1              1  \n",
      "105      1             0        1       0       1              1  \n",
      "176      1             0        1       1       1              1  \n",
      "218      1             0        1       0       1              1  \n",
      "238      1             0        1       0       1              1   \n",
      "\n",
      "toxic            0.926690\n",
      "severe_toxic     0.222776\n",
      "obscene          0.734520\n",
      "threat           0.069751\n",
      "insult           0.825623\n",
      "identity_hate    1.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first comment\n",
    "print(df[\"comment_text\"][0], \"\\n\")\n",
    "\n",
    "# And look at some identity_hate rows.\n",
    "# Trigger warning: this may contain slurs and other offensive language.\n",
    "print(df[df[\"identity_hate\"] == 1].head(), \"\\n\")\n",
    "\n",
    "# Look at outcome distribution among the identity hate observations.\n",
    "print(df[df[\"identity_hate\"] == 1][outcomes].mean(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqychOh2TYp9"
   },
   "outputs": [],
   "source": [
    "# This will take about 3 minutes.\n",
    "# TODO: also include test.csv for the language model training.\n",
    "data_lm = (TextList.from_csv(raw_data, 'train.csv', cols = \"comment_text\")\n",
    "             # Randomly split and keep 10% for validation of the language model.\n",
    "             .split_by_rand_pct(0.1)\n",
    "             .label_for_lm()           \n",
    "             .databunch(bs = bs))\n",
    "             \n",
    "# Type needs to be TextLMDataBunch for use in language model fine-tuning.\n",
    "print(type(data_lm))\n",
    "\n",
    "# This will be saved into the data-raw directory unfortunately.\n",
    "data_lm.save('data_lm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ir79ek3AHOKi",
    "outputId": "a642f8d3-fcfe-4b37-f284-8f60edc37354"
   },
   "outputs": [],
   "source": [
    "# The next time we run this notebook, skip above cell and load the preprocessed data.\n",
    "# If you get an error \"load_data does not exist\" then using too old of a fastai module.\n",
    "data_lm = load_data(raw_data, 'data_lm.pkl', bs=bs)\n",
    "# This should be a TextLMDataBunch\n",
    "type(data_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "3uf_iS33FeIF",
    "outputId": "42a646e1-4f51-46c6-8bd4-985425a78769"
   },
   "outputs": [],
   "source": [
    "data_lm.show_batch()\n",
    "\n",
    "# Examine vocabulary\n",
    "print(data_lm.vocab.itos[:15])\n",
    "\n",
    "# 60k tokens in our vocabulary\n",
    "print(len(data_lm.vocab.itos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFpuhBl8Agey"
   },
   "source": [
    "## Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQ47IWc1IUOd"
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "\n",
    "# Clear unused GPU memory, to help lr_find().\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nzLGkQw8PAkT",
    "outputId": "5934cbfb-ac1d-4554-db97-9458a699f477"
   },
   "outputs": [],
   "source": [
    "from fastai.utils.mem import gpu_mem_get\n",
    "gpu_mem_get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZChiqZAyIYSL",
    "outputId": "a7a12ec5-3e01-477d-cade-023a8474ccaa"
   },
   "outputs": [],
   "source": [
    "# This can give a RuntimeError if the GPU runs out of memory (\"CUDA out of memory\").\n",
    "# If this happens we need to use a smaller batch size.\n",
    "# GPU RAM usage is also affected by other running notebooks in Google Colab.\n",
    "# (See Runtime -> \"Manage sessions\" to delete old sessions.)\n",
    "# This will take about 1 minute.\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "c6qepgGsIa8T",
    "outputId": "3a2d95b1-a0a8-4d00-ef0d-591dcd5e4fa7"
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot(skip_end=12, skip_start=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "id": "70DpLmXTYEve",
    "outputId": "7602534a-23ca-4aed-ba41-6c259d94f8d0"
   },
   "outputs": [],
   "source": [
    "# This will take 46 minutes on Google Colab GPU! Accuracy after epoch 0: 21%\n",
    "# Takes only 7 minutes per epoch on FloydHub Tesla V100, with batch size of 160!\n",
    "learn.fit_one_cycle(1, 2e-1, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A0IpojjfYO2X"
   },
   "outputs": [],
   "source": [
    "learn.save('fit_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2791
    },
    "colab_type": "code",
    "id": "tgXAsAK8YPXI",
    "outputId": "3fc9625c-aa32-42bd-a182-dd90c6ded062"
   },
   "outputs": [],
   "source": [
    "learn.load(\"fit_head\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "6VDyNfNXYp3u",
    "outputId": "0880db43-1880-4872-cf19-439ee240368b"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "\n",
    "# 51 mins per epoch on Colab GPU, 7.5 per epoch on FloydHub v100\n",
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))\n",
    "\n",
    "# 2 mins / X mins\n",
    "learn.save('fine_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_7aNiR0Yzs7"
   },
   "outputs": [],
   "source": [
    "learn.load('fine_tuned');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYn49xz1Y3TY"
   },
   "outputs": [],
   "source": [
    "#TEXT = \"I liked this movie because\"\n",
    "TEXT = \"I hate myself for\"\n",
    "N_WORDS = 30\n",
    "N_SENTENCES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0esQI7wvY6Oi"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dbvacuC9Y-_O"
   },
   "outputs": [],
   "source": [
    "\n",
    "learn.save_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXISL7RmZGHX"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zf9v8iouZFbt"
   },
   "outputs": [],
   "source": [
    "# Following lesson3-imdb from fast.ai course 1\n",
    "# https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-imdb.ipynb\n",
    "\n",
    "# Define our outcome column. Other options shown in the cell output above.\n",
    "outcome = \"identity_hate\"\n",
    "\n",
    "# More documentation at https://docs.fast.ai/text.data.html\n",
    "# This will take about 2-3 minutes to run.\n",
    "# Other parameters: max_vocab (default 60k), min_freq (default 2), bs (default 64)\n",
    "data_clas = TextDataBunch.from_csv(raw_data, 'train.csv', text_cols = \"comment_text\", \\\n",
    "                              # Max_vocab needs to match the vocabulary size of the LM encoder\n",
    "                              max_vocab = 60000, \\\n",
    "                             # Reduce vocabulary size due to GPU memory constraints.\n",
    "                              #max_vocab = 20000, \\\n",
    "                              #max_vocab = 50000, \\\n",
    "                              # Limit batch size due to GPU memory constraints.\n",
    "                              label_cols = outcome, bs = bs)\n",
    "\n",
    "# This takes 45 seconds or so.\n",
    "data_clas.save('data_clas.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zR5lCuYBZcLZ"
   },
   "outputs": [],
   "source": [
    "# 160 bs is too big for FloydHub, 64 seems to work though.\n",
    "data_clas = load_data(raw_data, 'data_clas.pkl', bs = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "igNcjhyYZfuK"
   },
   "outputs": [],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19eex2rYZs5W"
   },
   "outputs": [],
   "source": [
    "# AUC callback code via https://forums.fast.ai/t/using-auc-as-metric-in-fastai/38917/7\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "# For average precision score see:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score\n",
    "\n",
    "def auroc_score(input, target):\n",
    "    input, target = input.cpu().numpy()[:,1], target.cpu().numpy()\n",
    "    return roc_auc_score(target, input)\n",
    "\n",
    "class callback_auc(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['auc'])\n",
    "    def on_epoch_begin(self, **kwargs): self.output, self.target = [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, train, **kwargs):\n",
    "        if not train:\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "                \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if len(self.output) > 0:\n",
    "            output = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            preds = F.softmax(output, dim=1)\n",
    "            metric = auroc_score(preds, target)\n",
    "            return add_metrics(last_metrics, [metric])\n",
    "        \n",
    "def prauc_score(input, target):\n",
    "    input, target = input.cpu().numpy()[:,1], target.cpu().numpy()\n",
    "    return average_precision_score(target, input)\n",
    "\n",
    "class callback_prauc(Callback):\n",
    "    # Run before recorder but after AUC callback\n",
    "    _order = -19\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['pr-auc'])\n",
    "    def on_epoch_begin(self, **kwargs): self.output, self.target = [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, train, **kwargs):\n",
    "        if not train:\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "                \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if len(self.output) > 0:\n",
    "            output = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            preds = F.softmax(output, dim=1)\n",
    "            metric = prauc_score(preds, target)\n",
    "            return add_metrics(last_metrics, [metric])\n",
    "\n",
    "# AWD = ASGD Weight-Dropped, ASGD = averaged stochastic gradient descent\n",
    "# See Merity et al. (2017) Regularizing and optimizing LSTM language models\n",
    "# Other model options here: https://docs.fast.ai/text.models.html\n",
    "# Transformer and TranformerXL are the main two alternatives currently.\n",
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, callback_fns = (callback_auc, callback_prauc))\n",
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YKVrhur-ZwZA"
   },
   "outputs": [],
   "source": [
    "# 10 seconds\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_K8i9__BZw0n"
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot(skip_end=7, skip_start = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5F-kKkgZygU"
   },
   "outputs": [],
   "source": [
    "# 3-4 mins on FloydHub, 99% accuracy, 0.85-0.87 AUC, PR-AUC 0.08\n",
    "learn.fit_one_cycle(1, 4e-1, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cyf9Pu5uZ2b-"
   },
   "outputs": [],
   "source": [
    "learn.save('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y04usv6oZ8eU"
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "# 4.5 minutes\n",
    "# AUC now up to 0.928, PR-AUC 0.243\n",
    "# Note that if we only looked at accuracy, it would seem to be doing worse.\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MN55R20DZ_Un"
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-3)\n",
    "# Some improvement: AUC now 0.949 and PR-AUC 0.343\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"third\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMGClFKVaDHv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 16:57 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>pr-auc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>0.953902</td>\n",
       "      <td>0.989535</td>\n",
       "      <td>0.951160</td>\n",
       "      <td>0.380817</td>\n",
       "      <td>08:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027963</td>\n",
       "      <td>1.236983</td>\n",
       "      <td>0.989660</td>\n",
       "      <td>0.954707</td>\n",
       "      <td>0.384531</td>\n",
       "      <td>08:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "# 8.5 then 9 minutes\n",
    "# AUC now up to 0.954 and PR-AUC 0.385 - great.\n",
    "# Do we need a slower learning rate?\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uPkHuTjMaHD9"
   },
   "source": [
    "## Prediction\n",
    "\n",
    "Trigger warning: we need to test some hateful speech in order for this to be a worthwhile exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our third model was best so far.\n",
    "#learn.load(\"third\");\n",
    "# Now our last model is best - random variation or something else?\n",
    "learn.load(\"last\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-KuyzfkaD0g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Category 1, tensor(1), tensor([1.9644e-04, 9.9980e-01]))\n",
      "(Category 0, tensor(0), tensor([0.7174, 0.2826]))\n",
      "(Category 0, tensor(0), tensor([0.9455, 0.0545]))\n",
      "(Category 0, tensor(0), tensor([0.9961, 0.0039]))\n"
     ]
    }
   ],
   "source": [
    "# Probability distributions look good!\n",
    "print(learn.predict(df[df[\"identity_hate\"] == 1][\"comment_text\"].iloc[4]))\n",
    "print(learn.predict(\"I hate dirty green people, kill them all!! So vile and disgusting!!! Fuck em\"))\n",
    "# Positive identity speech - still an increase in probability due to the identity terms.\n",
    "print(learn.predict(\"I am proud to be a brown Mexican immigrant latina\"))\n",
    "# Positive robot speech\n",
    "print(learn.predict(\"I am a happy deep learning algorithm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to perspective API?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrWu9BUpaO4M"
   },
   "outputs": [],
   "source": [
    "## Score on test\n",
    "## Generate export\n",
    "\n",
    "## Submit Kaggle entry (for posterity) using kaggle-cli"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "toxic-comments-kaggle-colab.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
